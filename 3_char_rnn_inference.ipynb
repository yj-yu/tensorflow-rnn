{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Packages Imported\n"
     ]
    }
   ],
   "source": [
    "# Import Packages\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import collections\n",
    "import argparse\n",
    "import time\n",
    "import os\n",
    "from six.moves import cPickle\n",
    "print (\"Packages Imported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'vocab_size' is 99\n"
     ]
    }
   ],
   "source": [
    "# Load chars and vocab\n",
    "load_dir = \"data/linux_kernel\"\n",
    "with open(os.path.join(load_dir, 'chars_vocab.pkl'), 'rb') as f:\n",
    "    chars, vocab = cPickle.load(f)\n",
    "vocab_size = len(vocab) \n",
    "print (\"'vocab_size' is %d\" % (vocab_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now, we are ready to make our RNN model with seq2seq\n",
    "### This network is for sampling, so we don't need batches for sequenes nor optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network Ready\n"
     ]
    }
   ],
   "source": [
    "# Important RNN parameters \n",
    "rnn_size   = 128\n",
    "num_layers = 2\n",
    "\n",
    "batch_size = 1 # <= In the training phase, these were both 50\n",
    "seq_length = 1\n",
    "\n",
    "def unit_cell():\n",
    "    return tf.contrib.rnn.BasicLSTMCell(rnn_size,state_is_tuple=True,reuse=tf.get_variable_scope().reuse)\n",
    "cell = tf.contrib.rnn.MultiRNNCell([unit_cell() for _ in range(num_layers)])\n",
    "\n",
    "input_data = tf.placeholder(tf.int32, [batch_size, seq_length])\n",
    "targets    = tf.placeholder(tf.int32, [batch_size, seq_length])\n",
    "istate     = cell.zero_state(batch_size, tf.float32)\n",
    "# Weigths \n",
    "with tf.variable_scope('rnnlm'):\n",
    "    softmax_w = tf.get_variable(\"softmax_w\", [rnn_size, vocab_size])\n",
    "    softmax_b = tf.get_variable(\"softmax_b\", [vocab_size])\n",
    "    with tf.device(\"/cpu:0\"):\n",
    "        embedding = tf.get_variable(\"embedding\", [vocab_size, rnn_size])\n",
    "        inputs = tf.split(tf.nn.embedding_lookup(embedding, input_data), seq_length, 1)\n",
    "        inputs = [tf.squeeze(_input, [1]) for _input in inputs]\n",
    "# Output\n",
    "def loop(prev, _):\n",
    "    prev = tf.nn.xw_plus_b(prev, softmax_w, softmax_b)\n",
    "    prev_symbol = tf.stop_gradient(tf.argmax(prev, 1))\n",
    "    return tf.nn.embedding_lookup(embedding, prev_symbol)\n",
    "\"\"\"\n",
    "    loop_function: If not None, this function will be applied to the i-th output\n",
    "    in order to generate the i+1-st input, and decoder_inputs will be ignored,\n",
    "    except for the first element (\"GO\" symbol).\n",
    "\"\"\" \n",
    "outputs, last_state = tf.contrib.rnn.static_rnn(cell, inputs, istate\n",
    "                , scope='rnnlm')\n",
    "output = tf.reshape(tf.concat(outputs, 1), [-1, rnn_size])\n",
    "logits = tf.nn.xw_plus_b(output, softmax_w, softmax_b)\n",
    "probs  = tf.nn.softmax(logits)\n",
    "print (\"Network Ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-14-9ae50d1c4ff9>:3: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "WARNING:tensorflow:From <ipython-input-14-9ae50d1c4ff9>:4: all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Please use tf.global_variables instead.\n",
      "data/linux_kernel/model.ckpt-8000\n",
      "INFO:tensorflow:Restoring parameters from data/linux_kernel/model.ckpt-8000\n"
     ]
    }
   ],
   "source": [
    "# Restore RNN\n",
    "sess = tf.Session()\n",
    "sess.run(tf.initialize_all_variables())\n",
    "saver = tf.train.Saver(tf.all_variables())\n",
    "ckpt  = tf.train.get_checkpoint_state(load_dir)\n",
    "\n",
    "print (ckpt.model_checkpoint_path)\n",
    "saver.restore(sess, ckpt.model_checkpoint_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finally, show what RNN has generated! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling Done. \n",
      "___________________________________________\n",
      "\n",
      "/* struct auditued oq,\n",
      "\t struct audit_enables can in a\n",
      " * the->module */\n",
      "\telse /* SMP a signals, ne-time bew releas for rebining routine  SIBGR.\n",
      " *\n",
      " *  Copy: state if exits/help6Counter don't be NULL field \"olp.\n",
      " *\n",
      " * The futexy.\n",
      " */\n",
      "void sysctl_sched_kobjed(&watchdalleep_state, int sys_timk_ops, *mask, struct filt, unsigned int sysctl_lock)\n",
      "{\n",
      "\tlocal_is_ns(data, processor_idre != module_info);\n",
      "\n",
      "\tspin_unlocked();\n",
      "}\n",
      "\n",
      "/*\n",
      " * Ses the usage head return to the imple5 into would are loaded?\n",
      " *\n",
      " *  200--<bind be queued init for a defall it\n",
      " * resources attach groups before op tasks\n",
      "\t * */\n",
      "\t\tput__wake_erent(kgelse_from_irqsave, (currno->it_signal->end, sizeof(ss, p)-1 || liz))\n",
      "\t\t\treturn -ENOMEM;\n",
      "\t}\n",
      "\n",
      "\tregister_buf_settimed(ac, up = -1]);\n",
      "\n",
      "\td = targh = 0;\n",
      "\tunsigned long load;\n",
      "\n",
      "\terror = kobject_add(b, *cgrtmp, __user == SOFDIRD:\n",
      "\t\twrite_patch(KERNET_PRINTEND_NORMASSOVE_REL), \"..time_lenkelitick(&current->owner, regiver))\n",
      "\t\t\tprintk(KERN_NABS\n",
      "\t\t\t\t\t\t(i++)-\t= nb);\n",
      "\t\t\t\tbreak;\n",
      "\t\t}\n",
      "\n",
      "\t\tbreak;\n",
      "\tcheck_unlock(th\n"
     ]
    }
   ],
   "source": [
    "# Sampling function\n",
    "def weighted_pick(weights):\n",
    "    t = np.cumsum(weights)\n",
    "    s = np.sum(weights)\n",
    "    return(int(np.searchsorted(t, np.random.rand(1)*s)))\n",
    "\n",
    "# Sample using RNN and prime characters\n",
    "prime = \"/* \"\n",
    "state = sess.run(cell.zero_state(1, tf.float32))\n",
    "for char in prime[:-1]:\n",
    "    x = np.zeros((1, 1))\n",
    "    x[0, 0] = vocab[char]\n",
    "    state = sess.run(last_state, feed_dict={input_data: x, istate:state})\n",
    "\n",
    "# Sample 'num' characters\n",
    "ret  = prime\n",
    "char = prime[-1] # <= This goes IN! \n",
    "num  = 1000\n",
    "for n in range(num):\n",
    "    x = np.zeros((1, 1))\n",
    "    x[0, 0] = vocab[char]\n",
    "    [probsval, state] = sess.run([probs, last_state]\n",
    "        , feed_dict={input_data: x, istate:state})\n",
    "    p      = probsval[0] \n",
    "    \n",
    "    sample = weighted_pick(p)\n",
    "    # sample = np.argmax(p)\n",
    "    \n",
    "    pred   = chars[sample]\n",
    "    ret    = ret + pred\n",
    "    char   = pred\n",
    "    \n",
    "print (\"Sampling Done. \\n___________________________________________\\n\")\n",
    "\n",
    "print (ret)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hope, it was good. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
