{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from IPython.display import Image\n",
    "\n",
    "# Import MINST handwritten digits data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Image of Yaktocat](http://i.ytimg.com/vi/0QI3xgXuB-Q/hqdefault.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data =  mnist.train.images.reshape([-1,28,28])\n",
    "train_labels = mnist.train.labels\n",
    "test_data = mnist.test.images.reshape([-1,28,28])\n",
    "test_labels = mnist.test.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 28, 28)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label number : 7\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nICnCDyRF+IGk/gdI2fgmLyiSUAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f23472a1cd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data_index = 9990     # 0 ~ 9999\n",
    "\n",
    "plt.imshow(test_data[data_index],cmap='gray')\n",
    "print ('Label number : ' + str(np.argmax(test_labels[data_index])))\n",
    "print (test_labels[data_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Network Parameters\n",
    "n_input = 28 # MNIST data input (img shape: 28*28)\n",
    "n_steps = 28 # timesteps\n",
    "n_classes = 10 # MNIST total classes (0-9 digits)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Draw Your Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tf Graph input\n",
    "x = tf.placeholder(\"float\", [None, n_steps, n_input])\n",
    "y = tf.placeholder(\"float\", [None, n_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Placeholder:0\", shape=(?, 28, 28), dtype=float32)\n",
      "Tensor(\"Placeholder_1:0\", shape=(?, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print (x)\n",
    "print (y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Image of Yaktocat](https://ml4a.github.io/images/figures/mnist_1layer.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multinomial regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_v = tf.reshape(x, [-1, 28*28])\n",
    "\n",
    "# n_input * n_input == 784\n",
    "weights = tf.Variable(tf.truncated_normal([n_input * n_input, n_classes]))\n",
    "biases = tf.Variable(tf.zeros([n_classes]))\n",
    "logit = tf.matmul(x_v, weights) + biases\n",
    "prediction = logit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Image of Yaktocat](https://ml4a.github.io/images/figures/mnist_2layers.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural Network prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "size_of_hidden = 128\n",
    "x_v = tf.reshape(x, [-1, 28*28])\n",
    "weights_1 = tf.Variable(tf.truncated_normal([n_input * n_input, size_of_hidden]))\n",
    "biases_1 = tf.Variable(tf.zeros([size_of_hidden]))\n",
    "logits_1 = tf.matmul(x_v, weights_1) + biases_1\n",
    "output_1 = tf.nn.relu(logits_1)\n",
    "\n",
    "weights_2 = tf.Variable(tf.truncated_normal([size_of_hidden, n_classes]))\n",
    "biases_2 = tf.Variable(tf.zeros([n_classes]))\n",
    "logit = tf.matmul(output_1, weights_2) + biases_2\n",
    "prediction = tf.sigmoid(logit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(784), Dimension(128)])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_1.get_shape()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DNN simple version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_v = tf.reshape(x, [-1, 28*28])\n",
    "hidden = tf.contrib.layers.fully_connected(x_v,size_of_hidden,activation_fn=tf.nn.relu)\n",
    "prediction = tf.contrib.layers.fully_connected(hidden,n_classes,activation_fn=tf.nn.sigmoid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Image of Yaktocat](https://www.packtpub.com/sites/default/files/Article-Images/B05478_image001.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kernel_size = 3\n",
    "input_channel = 1\n",
    "out_channel = 32\n",
    "hidden_node = 128\n",
    "keep_prob = 1\n",
    "\n",
    "layer1_weights = tf.Variable(tf.truncated_normal([kernel_size, kernel_size, input_channel, out_channel], stddev=0.1))\n",
    "layer1_biases = tf.Variable(tf.zeros([out_channel]))\n",
    "\n",
    "layer2_weights = tf.Variable(tf.truncated_normal([n_input // 4 * n_input // 4 * out_channel, hidden_node], stddev=0.1))\n",
    "layer2_biases = tf.Variable(tf.constant(0.01, shape=[hidden_node]))\n",
    "\n",
    "layer3_weights = tf.Variable(tf.truncated_normal([hidden_node, n_classes], stddev=0.1))\n",
    "layer3_biases = tf.Variable(tf.constant(0.01, shape=[n_classes]))\n",
    "\n",
    "x_cnn = tf.reshape(x, [-1,n_input,n_input,input_channel])\n",
    "\n",
    "conv = tf.nn.conv2d(x_cnn, filter=layer1_weights, strides=[1, 2, 2, 1], padding='VALID') \n",
    "hidden = tf.nn.relu(conv + layer1_biases)\n",
    "\n",
    "pool = tf.nn.max_pool(hidden, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "shape = pool.get_shape().as_list()\n",
    "reshape = tf.reshape(pool, [-1, shape[1] * shape[2] * shape[3]])\n",
    "\n",
    "hidden = tf.nn.relu(tf.matmul(reshape, layer2_weights) + layer2_biases)\n",
    "\n",
    "logit = tf.matmul(hidden, layer3_weights) + layer3_biases\n",
    "prediction= tf.sigmoid(logit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN simple version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_channel = 1\n",
    "out_channel = 32\n",
    "hidden_node = 128\n",
    "\n",
    "x_cnn = tf.reshape(x, [-1,28,28,input_channel])\n",
    "layer1 = tf.contrib.layers.conv2d(x_cnn,out_channel,kernel_size=3,activation_fn=tf.nn.relu, padding='SAME')\n",
    "pool1 = tf.nn.max_pool(layer1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "pool1_flat = tf.reshape(pool1, [-1, 14*14*out_channel])\n",
    "hidden = tf.contrib.layers.fully_connected(pool1_flat,hidden_node,activation_fn=tf.nn.relu)\n",
    "prediction = tf.contrib.layers.fully_connected(hidden,n_classes,activation_fn=tf.nn.sigmoid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'MaxPool_2:0' shape=(?, 14, 14, 16) dtype=float32>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Draw your own Best code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_cnn = tf.reshape(x, [-1,28,28,1])\n",
    "# Implement model!\n",
    "\n",
    "prediction = tf.contrib.layers.fully_connected(hidden,10,activation_fn=tf.nn.sigmoid)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reproduce this model!\n",
    "![Image of Yaktocat](http://7xi3e9.com1.z0.glb.clouddn.com/cnnmnist.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_cnn = tf.reshape(x, [-1,28,28,1])\n",
    "# Reproduce model!\n",
    "\n",
    "\n",
    "\n",
    "#layer1 = tf.contrib.layers.conv2d(x_cnn,32,kernel_size=5,activation_fn=tf.nn.relu, padding='SAME')\n",
    "#pool1 = tf.nn.max_pool(layer1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "#layer2 = tf.contrib.layers.conv2d(pool1,64,kernel_size=5,activation_fn=tf.nn.relu, padding='SAME')\n",
    "#pool2 = tf.nn.max_pool(layer2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "#pool2_flat = tf.reshape(pool2, [-1, 7*7*64])\n",
    "#hidden = tf.contrib.layers.fully_connected(pool2_flat,1024,activation_fn=tf.nn.relu)\n",
    "#hidden2 = tf.contrib.layers.fully_connected(hidden,1024,activation_fn=tf.nn.relu)\n",
    "\n",
    "prediction = tf.contrib.layers.fully_connected(hidden2,10,activation_fn=tf.nn.sigmoid)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Launch Your Graph : Start Training!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross Entropy Loss and Initialize all variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/yj/.virtualenvs/lecture/local/lib/python2.7/site-packages/tensorflow/python/util/tf_should_use.py:170: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.001\n",
    "\n",
    "# Define loss and optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=prediction, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# Evaluate model\n",
    "correct_pred = tf.equal(tf.argmax(prediction,1), tf.argmax(y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.initialize_all_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 10, Minibatch Loss=1.753315, Training Accuracy=0.74219\n",
      "Iter 20, Minibatch Loss=1.628806, Training Accuracy=0.81250\n",
      "Iter 30, Minibatch Loss=1.607062, Training Accuracy=0.80469\n",
      "Iter 40, Minibatch Loss=1.546684, Training Accuracy=0.91406\n",
      "Iter 50, Minibatch Loss=1.548314, Training Accuracy=0.89844\n",
      "Iter 60, Minibatch Loss=1.524664, Training Accuracy=0.93750\n",
      "Iter 70, Minibatch Loss=1.504262, Training Accuracy=0.95312\n",
      "Iter 80, Minibatch Loss=1.531224, Training Accuracy=0.92969\n",
      "Iter 90, Minibatch Loss=1.518533, Training Accuracy=0.93750\n",
      "Iter 100, Minibatch Loss=1.497614, Training Accuracy=0.95312\n",
      "Iter 110, Minibatch Loss=1.497169, Training Accuracy=0.96875\n",
      "Iter 120, Minibatch Loss=1.506083, Training Accuracy=0.91406\n",
      "Iter 130, Minibatch Loss=1.486125, Training Accuracy=0.96875\n",
      "Iter 140, Minibatch Loss=1.488708, Training Accuracy=0.96875\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-7a9c0d3ac4f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mbatch_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m# Run optimization op (backprop)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdisplay_step\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0;31m# Calculate batch accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yj/.virtualenvs/lecture/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    787\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 789\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    790\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yj/.virtualenvs/lecture/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    995\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 997\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    998\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yj/.virtualenvs/lecture/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1132\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1133\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/yj/.virtualenvs/lecture/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1137\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yj/.virtualenvs/lecture/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1119\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Launch the graph\n",
    "\n",
    "# Training Parameters\n",
    "training_iters = 100000\n",
    "batch_size = 128\n",
    "display_step = 10\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    step = 1\n",
    "    # Keep training until reach max iterations\n",
    "    while step * batch_size < training_iters:\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        # Reshape data to get 28 seq of 28 elements\n",
    "        batch_x = batch_x.reshape((batch_size, n_steps, n_input))\n",
    "        # Run optimization op (backprop)\n",
    "        sess.run(optimizer, feed_dict={x: batch_x, y: batch_y})\n",
    "        if step % display_step == 0:\n",
    "            # Calculate batch accuracy\n",
    "            acc = sess.run(accuracy, feed_dict={x: batch_x, y: batch_y})\n",
    "            # Calculate batch loss\n",
    "            loss = sess.run(cost, feed_dict={x: batch_x, y: batch_y})\n",
    "            print(\"Iter {}, Minibatch Loss={:.6f}, Training Accuracy={:.5f}\".format(step,\n",
    "                                                                                    loss, acc))\n",
    "        step += 1\n",
    "    print(\"Optimization Finished!\")\n",
    "\n",
    "    # Calculate accuracy for 128 mnist test images\n",
    "    test_len = 128\n",
    "    test_data = mnist.test.images[:test_len].reshape((-1, n_steps, n_input))\n",
    "    test_label = mnist.test.labels[:test_len]\n",
    "    print(\"Testing Accuracy:{}\".format(sess.run(accuracy, feed_dict={x: test_data, y: test_label})))\n",
    "    predicted_prob = sess.run(prediction, feed_dict={x: test_data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 10)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_prob.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result Analysis!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrong answer list : \n",
      "[8, 73, 80, 92]\n"
     ]
    }
   ],
   "source": [
    "wrong_list=np.where(np.argmax(predicted_prob,1) != np.argmax(test_label,1))[0].tolist()\n",
    "print (\"Wrong answer list : \")\n",
    "print (wrong_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Label number : 6\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2363baa3d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "for ind in wrong_list:\n",
    "    print ('Predicted Label number : ' + str(np.argmax(predicted_prob[ind])))\n",
    "    plt.imshow(test_data[ind],cmap='gray')\n",
    "    plt.show()\n",
    "    a = input('Next plot?\\n')\n",
    "    if a == 'q':\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lenet - 1 CNN의 전신"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "![Image of Yaktocat](http://blogthumb2.naver.net/20160307_154/laonple_1457362135978fdcpT_JPEG/1.jpg?type=w2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lenet - 5 : Convolution + fully connected network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Image of Yaktocat](https://i1.read01.com/uploads/0F0bSLiV4J.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "초기 MNIST 성능비교\n",
    "![Image of Yaktocat](http://postfiles7.naver.net/20160307_246/laonple_14573621369260G69J_JPEG/3.jpg?type=w2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
