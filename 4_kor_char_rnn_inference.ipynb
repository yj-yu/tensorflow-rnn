{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample Hangul RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Packages Imported\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# Import Packages\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import collections\n",
    "import string\n",
    "import argparse\n",
    "import time\n",
    "import os\n",
    "from six.moves import cPickle\n",
    "from TextLoader import *\n",
    "from Hangulpy import *\n",
    "print (\"Packages Imported\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset using TextLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading preprocessed files\n",
      "type of 'data_loader' is <type 'dict'>, length is 76\n",
      "\n",
      "\n",
      "data_loader.vocab looks like \n",
      "{u'_': 69, u'6': 59, u':': 57, u'\\n': 19, u'4': 67, u'5': 63, u'>': 75, u'!': 52, u' ': 1, u'\"': 28, u'\\u1d25': 0, u\"'\": 49, u')': 46, u'(': 45, u'-': 65, u',': 27, u'.': 24, u'\\u3131': 7, u'0': 73, u'\\u3133': 60, u'\\u3132': 29, u'\\u3135': 50, u'\\u3134': 4, u'\\u3137': 13, u'\\u3136': 44, u'\\u3139': 5, u'\\u3138': 32, u'\\u313b': 55, u'\\u313a': 48, u'\\u313c': 54, u'?': 41, u'3': 66, u'\\u3141': 12, u'\\u3140': 51, u'\\u3143': 47, u'\\u3142': 17, u'\\u3145': 10, u'\\u3144': 43, u'\\u3147': 2, u'\\u3146': 22, u'\\u3149': 40, u'\\u3148': 15, u'\\u314b': 42, u'\\u314a': 23, u'\\u314d': 31, u'\\u314c': 30, u'\\u314f': 3, u'\\u314e': 14, u'\\u3151': 34, u'\\u3150': 21, u'\\u3153': 11, u'\\u3152': 74, u'\\u3155': 18, u'\\u3154': 20, u'\\u3157': 9, u'\\u3156': 39, u'\\u3159': 53, u'\\u3158': 26, u'\\u315b': 38, u'\\u315a': 33, u'\\u315d': 36, u'\\u315c': 16, u'\\u315f': 35, u'\\u315e': 61, u'\\u3161': 8, u'\\u3160': 37, u'\\u3163': 6, u'\\u3162': 25, u'\\x1a': 72, u'9': 64, u'7': 71, u'2': 62, u'1': 58, u'\\u313f': 56, u'\\u313e': 70, u'8': 68} \n",
      "\n",
      "\n",
      "type of 'data_loader.chars' is <type 'tuple'>, length is 76\n",
      "\n",
      "\n",
      "data_loader.chars looks like \n",
      "(u'\\u1d25', u' ', u'\\u3147', u'\\u314f', u'\\u3134', u'\\u3139', u'\\u3163', u'\\u3131', u'\\u3161', u'\\u3157', u'\\u3145', u'\\u3153', u'\\u3141', u'\\u3137', u'\\u314e', u'\\u3148', u'\\u315c', u'\\u3142', u'\\u3155', u'\\n', u'\\u3154', u'\\u3150', u'\\u3146', u'\\u314a', u'.', u'\\u3162', u'\\u3158', u',', u'\"', u'\\u3132', u'\\u314c', u'\\u314d', u'\\u3138', u'\\u315a', u'\\u3151', u'\\u315f', u'\\u315d', u'\\u3160', u'\\u315b', u'\\u3156', u'\\u3149', u'?', u'\\u314b', u'\\u3144', u'\\u3136', u'(', u')', u'\\u3143', u'\\u313a', u\"'\", u'\\u3135', u'\\u3140', u'!', u'\\u3159', u'\\u313c', u'\\u313b', u'\\u313f', u':', u'1', u'6', u'\\u3133', u'\\u315e', u'2', u'5', u'9', u'-', u'3', u'4', u'8', u'_', u'\\u313e', u'7', u'\\x1a', u'0', u'\\u3152', u'>') \n"
     ]
    }
   ],
   "source": [
    "corpus_name = \"invisible_dragon\" # \"nine_dreams\"\n",
    "# corpus_name = \"nine_dreams\"\n",
    "\n",
    "data_dir    = \"data/\" + corpus_name\n",
    "batch_size  = 10\n",
    "seq_length  = 100\n",
    "data_loader = TextLoader(data_dir, batch_size, seq_length)\n",
    "# This makes \"vocab.pkl\" and \"data.npy\" in \"data/nine_dreams\"   \n",
    "#  from \"data/nine_dreams/input.txt\" \n",
    "vocab_size = data_loader.vocab_size\n",
    "vocab = data_loader.vocab\n",
    "chars = data_loader.chars\n",
    "print ( \"type of 'data_loader' is %s, length is %d\" \n",
    "       % (type(data_loader.vocab), len(data_loader.vocab)) )\n",
    "print ( \"\\n\" )\n",
    "print (\"data_loader.vocab looks like \\n%s \" %\n",
    "       (data_loader.vocab))\n",
    "print ( \"\\n\" )\n",
    "print ( \"type of 'data_loader.chars' is %s, length is %d\" \n",
    "       % (type(data_loader.chars), len(data_loader.chars)) )\n",
    "print ( \"\\n\" )\n",
    "print (\"data_loader.chars looks like \\n%s \" % (data_loader.chars,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network Ready\n"
     ]
    }
   ],
   "source": [
    "rnn_size   = 512\n",
    "num_layers = 3\n",
    "grad_clip  = 5.\n",
    "\n",
    "_batch_size = 1\n",
    "_seq_length = 1\n",
    "\n",
    "vocab_size = data_loader.vocab_size\n",
    "\n",
    "with tf.device(\"/cpu:0\"):\n",
    "    # Select RNN Cell\n",
    "    def unit_cell():\n",
    "        return tf.contrib.rnn.BasicLSTMCell(rnn_size,state_is_tuple=True,reuse=tf.get_variable_scope().reuse)\n",
    "    cell = tf.contrib.rnn.MultiRNNCell([unit_cell() for _ in range(num_layers)])\n",
    "\n",
    "    # Set paths to the graph \n",
    "    input_data = tf.placeholder(tf.int32, [_batch_size, _seq_length])\n",
    "    targets    = tf.placeholder(tf.int32, [_batch_size, _seq_length])\n",
    "    initial_state = cell.zero_state(_batch_size, tf.float32)\n",
    "\n",
    "    # Set Network\n",
    "    with tf.variable_scope('rnnlm'):\n",
    "        softmax_w = tf.get_variable(\"softmax_w\", [rnn_size, vocab_size])\n",
    "        softmax_b = tf.get_variable(\"softmax_b\", [vocab_size])\n",
    "        with tf.device(\"/cpu:0\"):\n",
    "            embedding = tf.get_variable(\"embedding\", [vocab_size, rnn_size])\n",
    "            inputs = tf.split(tf.nn.embedding_lookup(embedding, input_data), _seq_length, 1)\n",
    "            inputs = [tf.squeeze(input_, [1]) for input_ in inputs]\n",
    "            \n",
    "    # Loop function for seq2seq\n",
    "    def loop(prev, _):\n",
    "        prev = tf.nn.xw_plus_b(prev, softmax_w, softmax_b)\n",
    "        prev_symbol = tf.stop_gradient(tf.argmax(prev, 1))\n",
    "        return tf.nn.embedding_lookup(embedding, prev_symbol)\n",
    "    # Output of RNN \n",
    "    outputs, last_state = tf.contrib.rnn.static_rnn(cell,inputs, initial_state\n",
    "                                , scope='rnnlm')\n",
    "    output = tf.reshape(tf.concat(outputs,1), [-1, rnn_size])\n",
    "    logits = tf.nn.xw_plus_b(output, softmax_w, softmax_b)\n",
    "    # Next word probability \n",
    "    probs = tf.nn.softmax(logits)\n",
    "    final_state = last_state\n",
    "\n",
    "print (\"Network Ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampling function done.\n"
     ]
    }
   ],
   "source": [
    "# Sample ! \n",
    "def sample( sess, chars, vocab, __probs, num=200, prime=u'ㅇㅗᴥㄴㅡㄹᴥ '):\n",
    "    state = sess.run(cell.zero_state(1, tf.float32))\n",
    "    _probs = __probs\n",
    "    prime = list(prime)\n",
    "    for char in prime[:-1]:\n",
    "        x = np.zeros((1, 1))\n",
    "        x[0, 0] = vocab[char]\n",
    "        feed = {input_data: x, initial_state:state}\n",
    "        [state] = sess.run([last_state], feed)\n",
    "\n",
    "    def weighted_pick(weights):\n",
    "        weights = weights / np.sum(weights) \n",
    "        t = np.cumsum(weights)\n",
    "        s = np.sum(weights)\n",
    "        return(int(np.searchsorted(t, np.random.rand(1)*s)))\n",
    "\n",
    "    ret = prime\n",
    "    char = prime[-1]\n",
    "    for n in range(num):\n",
    "        x = np.zeros((1, 1))\n",
    "        x[0, 0] = vocab[char]\n",
    "        feed = {input_data: x, initial_state:state}\n",
    "        [_probsval, state] = sess.run([_probs, final_state], feed)\n",
    "        p = _probsval[0]\n",
    "        sample = int(np.random.choice(len(p), p=p))\n",
    "        #sample = weighted_pick(p)\n",
    "        pred = chars[sample]\n",
    "        ret += pred\n",
    "        char = pred\n",
    "    return ret\n",
    "print (\"sampling function done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prime Text :   =>  \n",
      "WARNING:tensorflow:From <ipython-input-6-301c77642b1f>:8: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "WARNING:tensorflow:From <ipython-input-6-301c77642b1f>:9: all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Please use tf.global_variables instead.\n",
      "data/nine_dreams/model.ckpt-99000\n",
      "INFO:tensorflow:Restoring parameters from data/nine_dreams/model.ckpt-99000\n",
      "-- RESULT --\n",
      " 그러하도다.\"\n",
      "  하였다. \n",
      "  태사가 먼저 승상을 모시고 꿇어앉아 사은한 읏을 일어컴기고 구녀를 지어 소뉘가 일어나 나건대 가는 기숙이 묽고\n",
      "  ㅘㅏ이에게 작은의 몸이 문륵기지 못함이면, 이 상군이 사람을 비어 조그마한 배 \n",
      "형의 희랑찬이라, 다시 한백 밖에 \n",
      "도려보지 못하였는데, 이쩨 양소유가 지어 자주 구공문을 듣더니 이를 것 \n",
      "넌작진자가 봄기 간경차항여 가볍겠고서는, 부친의 황자우로 돌아와 \n",
      "몸다뱅 앞에 \n",
      "가히 공주를 헤리려 하소.\"\n",
      " 만뜻 사랑으로 밤깝스시면 내가 슨편하시게 돌아오로 \n",
      "아되에 월업과 깨받이 연끼라 하시니, 상이 여정이 저저를 바라보니, 공주가 \n",
      "한가의 배하를 진적없게 하지만 그 잔치에게 말하다.\"\n",
      "  유부인의 별당으로 돌아오시고 공며(소기와 옥다하였음이데다. 싶삽상이 부슬되었나이다.\"\n",
      "  하기에, 춘운이 군사를 듣고 대사로 부처늠꾸로 이번과도 국제호 내일 꺼리지 \n",
      "않소. 무슨 전이 많을 임금도 얻으면 기대를 \n",
      "진중하라 행상 제자 동남을 탕부, 못항즙 따라짔다. \n",
      "  이에 승상이 정색의 해설하지는 일을 햍치고 죽은 전에 사귀와 \n",
      "맞아들이게 좋아히 그 산 몸을 굽어들었소이다. 다시 날을 떠로함이 없는 눈갈가 아지 \n",
      "못하였는데 그 때에 이느로부터늬 부니를 위하여 경추라고 하직인지라. 노조가 \n",
      "팔선녀에게 맞ㅈ주시고 다휘오지 않사옵거늘 곧 이미 항면 밖 사실이니, 화역히 \n",
      "간박하고 귀공자 장원은 직제의 의섬으로 더 갑후 펴겨 \n",
      "주쇠.기를 삼에 대답지 못하오리며, 하늘이니 온다) 환상폐 풍욱술교가(소자와의 분운의 위엄이 있삽관을 가히 \n",
      "보내지 아니하라. 그러니 말은즉 선도 나무 그림자는 \n",
      "곳에 우르되\n",
      "\n",
      "  \"우는 손이로소유! 한교제는 아내로 우덥게 말했다. \n",
      "  \"바라매 웃으니 노해도 멀어 자리를 바람과 같이할 사람이 없나이다.\"\n",
      "  하고 이에 격막(추의 여용)의 안봉에 과거의 긑은 여마를 아래자 차자 피와를 떠나졌다. \n",
      "  양대가 엻은 화례한 경개를 구려 보이고 회고, \n",
      "밝은 날 새적으로 보았다. \n",
      "  시자가 대답하기를, \n",
      "  \"계랑이 다시 여기어 검무를 타고 한탐을 들은 자리에 있사와 무사히 내 양소유의 평치른 뒤다르지 \n",
      "못하겠거늘, 난양이 또한 양ㅅ계로 자리 위하니, \n",
      "양소유는 사양을 월루하고 온미화도 \n",
      "직시었다. 운양하거나 여자의 몸이 사혼하되\n",
      "  \"봉으로 도사가 만날 서 엿음을 의통하여 절하고 백련호 탕복하굿에 \n",
      "있는데 기생 대감 무녀지 안반이 여사하오\n",
      "  양상서의 영양 공주의 두 사람의 옥영임을 이꿍 방밤이 아니니 잘 서의 기른 차가 \n",
      "있고, 내가 자주한 \n",
      "사람이 되게 하며 내 죄란 시금으로 태히 \n",
      "연전이 이미 어리사와 성진이 두어 결을 달리 두 정수의 소리가)올 구쳬를 거역한 규주. 행모에게 찬방에 이르러 \n",
      "희법여 난자와 석종 복, 옫기는 얼로 하지 않을 것이오.\"\n",
      "  이에 진어사가 내 상글로 쓸 수 잆으 모와 역색과 공주 인자하고 \n",
      "백명은 \n",
      "없고 온데 가히 남해 높이 상를 맞으매 온 앗을 양소유의 상설과 \n",
      "소첩을 명시기 사양하자가 \n",
      "사람이 떠나시다. \n",
      "  이제 춘랑안적(다냥의 미선들이 절동 사람이 아니라 함이거늘, 군사를 태해 무덤굽고 밖에서 두\n"
     ]
    }
   ],
   "source": [
    "save_dir = 'data/' + corpus_name\n",
    "prime = decompose_text(u\" \")\n",
    "\n",
    "print (\"Prime Text : %s => %s\" % (automata(prime), \"\".join(prime)))\n",
    "n = 4000\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.initialize_all_variables())\n",
    "saver = tf.train.Saver(tf.all_variables())\n",
    "ckpt = tf.train.get_checkpoint_state(save_dir)\n",
    "\n",
    "# load_name = u'data/nine_dreams/model.ckpt-0'\n",
    "load_name = os.path.join(save_dir,'model.ckpt-99000')\n",
    "\n",
    "print (load_name)\n",
    "\n",
    "if ckpt and ckpt.model_checkpoint_path:\n",
    "    saver.restore(sess, load_name)\n",
    "    sampled_text = sample(sess, chars, vocab, probs, n, prime)\n",
    "    #print (\"\")\n",
    "#     print (u\"SAMPLED TEXT = %s\" % sampled_text)\n",
    "#     print (\"\")\n",
    "    print (\"-- RESULT --\")\n",
    "    print (automata(\"\".join(sampled_text)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It takes long time to train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
